{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX to TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_engine(onnx, im, file, half, dynamic, workspace=4, verbose=False, prefix='Tensorrt'):\n",
    "    logger = trt.Logger(trt.Logger.INFO)\n",
    "    if verbose:\n",
    "        logger.min_severity = trt.Logger.Severity.VERBOSE\n",
    "\n",
    "    builder = trt.Builder(logger)\n",
    "    config = builder.create_builder_config()\n",
    "    config.max_workspace_size = workspace * 1 << 30\n",
    "    # config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, workspace << 30)  # fix TRT 8.4 deprecation notice\n",
    "\n",
    "    flag = (1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    network = builder.create_network(flag)\n",
    "    parser = trt.OnnxParser(network, logger)\n",
    "    if not parser.parse_from_file(str(onnx)):\n",
    "        raise RuntimeError(f'failed to load ONNX file: {onnx}')\n",
    "\n",
    "    inputs = [network.get_input(i) for i in range(network.num_inputs)]\n",
    "    outputs = [network.get_output(i) for i in range(network.num_outputs)]\n",
    "    for inp in inputs:\n",
    "        print(f'{prefix} input \"{inp.name}\" with shape{inp.shape} {inp.dtype}')\n",
    "    for out in outputs:\n",
    "        print(f'{prefix} output \"{out.name}\" with shape{out.shape} {out.dtype}')\n",
    "    \n",
    "    if dynamic:\n",
    "        profile = builder.create_optimization_profile()\n",
    "        for inp in inputs:\n",
    "            profile.set_shape(inp.name, (-1, *im.shape[1:]), (max(1, im.shape[0] // 2), *im.shape[1:]), im.shape)\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "    print(f'{prefix} building FP{16 if builder.platform_has_fast_fp16 and half else 32} engine')\n",
    "    if builder.platform_has_fast_fp16 and half:\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "    with builder.build_engine(network, config) as engine, open(file, 'wb') as t:\n",
    "        t.write(engine.serialize())\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = \"./deepc.onnx\"\n",
    "TRT_PATH = ONNX_PATH.replace('.onnx', '.engine')\n",
    "C, H, W = (1, 240, 320)\n",
    "\n",
    "device = 'cuda'\n",
    "inputs = torch.randn(1, C, H, W).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = \"./refinenet.onnx\"\n",
    "TRT_PATH = ONNX_PATH.replace('.onnx', '.engine')\n",
    "C, H, W = (1, 24, 24)\n",
    "\n",
    "device = 'cuda'\n",
    "inputs = torch.randn(1, C, H, W).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29679/3313887502.py:8: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = workspace * 1 << 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/05/2023-12:30:52] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[05/05/2023-12:30:52] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1960, GPU 1049 (MiB)\n",
      "[05/05/2023-12:30:52] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/05/2023-12:30:52] [TRT] [I] Input filename:   ./deepc.onnx\n",
      "[05/05/2023-12:30:52] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[05/05/2023-12:30:52] [TRT] [I] Opset version:    14\n",
      "[05/05/2023-12:30:52] [TRT] [I] Producer name:    pytorch\n",
      "[05/05/2023-12:30:52] [TRT] [I] Producer version: 1.13.1\n",
      "[05/05/2023-12:30:52] [TRT] [I] Domain:           \n",
      "[05/05/2023-12:30:52] [TRT] [I] Model version:    0\n",
      "[05/05/2023-12:30:52] [TRT] [I] Doc string:       \n",
      "[05/05/2023-12:30:52] [TRT] [I] ----------------------------------------------------------------\n",
      "Tensorrt input \"input\" with shape(-1, 1, 240, 320) DataType.FLOAT\n",
      "Tensorrt output \"output\" with shape(-1, 65, 30, 40) DataType.FLOAT\n",
      "Tensorrt output \"109\" with shape(-1, 17, 30, 40) DataType.FLOAT\n",
      "[05/05/2023-12:30:52] [TRT] [E] 3: [optimizationProfile.cpp::setDimensions::133] Error Code 3: API Usage Error (Parameter check failed at: runtime/common/optimizationProfile.cpp::setDimensions::133, condition: std::all_of(dims.d, dims.d + dims.nbDims, [](int32_t x) noexcept { return x >= 0; })\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Shape provided for min is inconsistent with other shapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexport_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mONNX_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mexport_engine\u001b[0;34m(onnx, im, file, half, dynamic, workspace, verbose, prefix)\u001b[0m\n\u001b[1;32m     25\u001b[0m     profile \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_optimization_profile()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 27\u001b[0m         \u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     config\u001b[38;5;241m.\u001b[39madd_optimization_profile(profile)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m building FP\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mplatform_has_fast_fp16 \u001b[38;5;129;01mand\u001b[39;00m half \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m32\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m engine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Shape provided for min is inconsistent with other shapes."
     ]
    }
   ],
   "source": [
    "export_engine(ONNX_PATH, inputs, TRT_PATH, False, True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with TRT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]: %load_ext autoreload\n",
    "\n",
    "In [2]: %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached TensorRT engine from ./deepc.engine\n",
      "input\n",
      "output\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import utils_engine as engine_utils # TRT Engine creation/save/load utils\n",
    "\n",
    "from time import time\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "TRT_PATH = \"./deepc.engine\"\n",
    "\n",
    "# SETUP TRT\n",
    "logger = trt.Logger(trt.Logger.ERROR)\n",
    "trt_runtime = trt.Runtime(logger)\n",
    "\n",
    "print(\"Loading cached TensorRT engine from {}\".format(TRT_PATH))\n",
    "trt_engine = engine_utils.load_engine(trt_runtime, TRT_PATH)\n",
    "\n",
    "# This allocates memory for network inputs/outputs on both CPU and GPU\n",
    "inputs, outputs, bindings, stream = engine_utils.allocate_buffers(trt_engine)\n",
    "\n",
    "# Execution context is needed for inference\n",
    "context = trt_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78000,) (20400,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare input data\n",
    "IMG_PATH = \"/home/adryw/Documents/deepcharuco/data_demo/test_frames/output_0005.png\"\n",
    "img = cv2.cvtColor(cv2.imread(IMG_PATH), cv2.COLOR_BGR2GRAY)\n",
    "img = (img.astype(np.float32) - 128) / 255  # Well we started with this one so...\n",
    "org_h, org_w = img.shape[:2]\n",
    "img_input = cv2.resize(img, (320, 240), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Copy it into appropriate place into memory\n",
    "# (inputs was returned earlier by allocate_buffers())\n",
    "np.copyto(inputs[0].host, img_input.ravel())\n",
    "\n",
    "# Feed to model\n",
    "tic = time()\n",
    "bs = 1\n",
    "# Fetch output from the model\n",
    "b_loc, b_ids = engine_utils.do_inference(\n",
    "    context, bindings=bindings, inputs=inputs,\n",
    "    outputs=outputs, stream=stream)\n",
    "print(b_loc.shape, b_ids.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
